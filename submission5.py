# -*- coding: utf-8 -*-
"""submission5.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1NhAgkehWT1RKuPuqyagFYHay_ZqkFdfJ

# **Gold Price Predictive Analytics**
Dataset: https://www.kaggle.com/datasets/sid321axn/gold-price-prediction-dataset

Topik yang dipilih dalam proyek machine learning ini adalah mengenai keuangan dengan judul proyek "Gold Price Predictive Analytics".

# Data Loading

### Import Library
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import pandas as pd
import tensorflow as tf
import matplotlib.pyplot as plt
# %matplotlib inline

df = pd.read_csv('/content/FINAL_USO.csv')
df.sort_values(by=['Date'], inplace=True, ascending=True)
df.set_index('Date', inplace= True)
df

"""# Exploratory Data Analysis"""

df.info()

"""### Menghilangkan kolum yang tidak diperlukan"""

df.drop(['Open'], inplace=True, axis=1)
df.drop(df.iloc[:, 2:80], inplace=True, axis=1)
df['Price_Average'] = (df['High'] + df['Low']) / 2
df

df.describe()

"""Output kode di atas memberikan informasi statistik pada masing-masing kolom, antara lain:

* count adalah jumlah sampel pada data.
* mean adalah nilai rata-rata.
* std adalah standar deviasi.
* min yaitu nilai minimum setiap kolom.
* 25% adalah kuartil pertama. Kuartil adalah nilai yang menandai batas * * interval dalam empat bagian sebaran yang sama.
* 50% adalah kuartil kedua, atau biasa juga disebut median (nilai tengah).
* 75% adalah kuartil ketiga.
* Max adalah nilai maksimum
"""

df['Price_NextMonth']=df['Price_Average'].shift(-30)
df

"""# Mengidentifikasi Missing Value dan Outlier

### Missing Value
"""

df.isnull().sum()

"""Setelah dilakukan pengecekan terdapat 30 _missing value_ pada dataset yaitu pada kolom _Price__NextMonth_, namun tidak apa - apa dikarenakan 30 value tersebut adalah harga emas di bulan berikutnya sehingga value tersebut adalah 0

### Outliers
"""

import seaborn as sns
plt.subplots(figsize=(10,7))
sns.boxplot(data=df).set_title("Gold Price")
plt.show()

"""Cukup banyak _outliers_ pada dataset, namun kita tidak akan menghapus semua outliers pada data dikarenakan jika kita menghapus outliers dengan contoh menggunakan metode InterQuartile Range (IQR), maka akan berdampak pada menurunnya tingkat akurasi pada model yang akan kita kerjakan nantinya

# Univariate Analysis
"""

df.hist(bins=50, figsize=(20,15))
plt.show()

"""Dari hasil histogram diatas dapat disimpulkan bahwasannya hampir semua variabel Distribusi nilainya miring ke kanan (right-skewed). Hal ini akan berimplikasi pada model nantinya.

# Multivariate Analysis
"""

sns.pairplot(df, diag_kind = 'kde')

"""Pada gambar diatas bisa kita lihat bahwa kebanyakan data memiliki korelasi positif yang ditandai dengan meningkatnya variabel pada sumbu y saat terjadi peningkatan variabel pada sumbu x. Selain itu ada juga data yang memiliki sebaran data acak yaitu pada grafik Volume."""

plt.figure(figsize=(10, 8))
correlation_matrix = df.corr().round(2)
sns.heatmap(data=correlation_matrix, annot=True, cmap='coolwarm', linewidths=0.5, )
plt.title("Correlation Matrix untuk Fitur Numerik ", size=20)

"""Terlihat pada matriks korelasi di atas dapat disimpulkan bahwa kebanyakan variabel memiliki keterikatan dan korelasi yang cukup kuat antar variabel lainnya, dimana nilai korelasi antar variabel bernilai lebih dari 0.9 atau mendekati 1.

# Data Preparation

Melakukan split data train test
"""

from sklearn import preprocessing
df.dropna(inplace=True)
X = df.drop('Price_NextMonth',axis=1)

X = preprocessing.scale(X)
y = df['Price_NextMonth']

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, train_size = 0.8, test_size = 0.2, random_state = 100)

print(f'Jumlah seluruh dataset: {len(X)}')
print(f'Jumlah train: {len(X_train)}')
print(f'Jumlah test: {len(X_test)}')

"""## Standardisasi

Melakukan standardisasi pada data train dan test
"""

from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
scaler.fit(X_train)
X_train = scaler.transform(X_train)
X_test = scaler.transform(X_test)

"""# Model Development"""

models = pd.DataFrame(index=['train_mse', 'test_mse'], 
                      columns=['KNN', 'RandomForest', 'Boosting'])

"""### K-Nearest Neighbor"""

from sklearn.neighbors import KNeighborsRegressor
knn = KNeighborsRegressor(n_neighbors=100)
knn.fit(X_train, y_train)
y_pred_knn = knn.predict(X_train)

"""### Random Forest"""

from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error
RF = RandomForestRegressor(n_estimators=100, max_depth=32, random_state=55, n_jobs=-1)
RF.fit(X_train, y_train)
models.loc['train_mse','RandomForest'] = mean_squared_error(y_pred=RF.predict(X_train), y_true=y_train)

"""### XGBoost Algorithm"""

from xgboost import XGBRegressor
xgbr = XGBRegressor()
xgbr.fit(X_train,y_train)

"""# Evaluation"""

mse = pd.DataFrame(columns=['train', 'test'], index=['KNN','RF','XGBR'])
model_dict = {'KNN': knn, 'RF': RF, 'XGBR': xgbr}
for name, model in model_dict.items():
    mse.loc[name, 'train'] = mean_squared_error(y_true=y_train, y_pred=model.predict(X_train))/1e3 
    mse.loc[name, 'test'] = mean_squared_error(y_true=y_test, y_pred=model.predict(X_test))/1e3
 
mse

fig, ax = plt.subplots()
mse.sort_values(by='test', ascending=False).plot(kind='barh', ax=ax, zorder=3)
ax.grid(zorder=0)

knn_accuracy_train = knn.score(X_train, y_train)*100
rf_accuracy_train = RF.score(X_train, y_train)*100
xgbr_accuracy_train = xgbr.score(X_train, y_train)*100

knn_accuracy_test = knn.score(X_test, y_test)*100
rf_accuracy_test = RF.score(X_test, y_test)*100
xgbr_accuracy_test = xgbr.score(X_test, y_test)*100

list_evaluasi = [[knn_accuracy_train],
            [rf_accuracy_train],
            [xgbr_accuracy_train]]
evaluasi = pd.DataFrame(list_evaluasi,
                        columns=['Accuracy (%)'],
                        index=['K-Nearest Neighbor', 'Random Forest', 'xgbr'])
evaluasi

"""## Prediction using XGBR Boosting"""

import matplotlib.pyplot as plt
X_testy,y_testy = X[int(0.8*len(df)):len(df)],y[int(0.8*len(df)):len(df)]

y_pred = xgbr.predict(X_testy)

x_test_label = range(len(y_testy))
x_pred_label = range(len(y_pred))
plt.plot(x_test_label,y_testy,label="original")
plt.plot(x_pred_label,y_pred,label="prediction")
plt.legend()
plt.show()